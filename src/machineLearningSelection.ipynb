{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import tools\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\r\n",
    "from sklearn.metrics import plot_roc_curve, classification_report\r\n",
    "from confusion_matrix.confusion_matrix import plot_confusion_matrix_from_data\r\n",
    "import joblib\r\n",
    "\r\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
    "from sklearn.manifold import LocallyLinearEmbedding\r\n",
    "from sklearn.random_projection import SparseRandomProjection\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "from importlib import reload\r\n",
    "reload(tools)\r\n",
    "directory = '../data/data_final'\r\n",
    "database = '../data/data_final/database.csv'\r\n",
    "\r\n",
    "X, y = tools.getDataTransformed(database, directory)\r\n",
    "X_train_origin, X_test_origin, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "dimention_reduction = [PCA, TruncatedSVD, LocallyLinearEmbedding, SparseRandomProjection] # LinearDiscriminantAnalysis,\r\n",
    "techniques = [RandomForestClassifier(), KNeighborsClassifier(), SVC(), AdaBoostClassifier(), XGBClassifier(use_label_encoder=False, eval_metric='logloss')]\r\n",
    "grid_params =[\r\n",
    "    {\r\n",
    "        'n_estimators': np.arange(10, 511, 100),\r\n",
    "        'criterion': ['gini', 'entropy']\r\n",
    "    },\r\n",
    "    {\r\n",
    "        'n_neighbors': np.arange(1,20, 3),\r\n",
    "        'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\r\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\r\n",
    "    },\r\n",
    "    {\r\n",
    "        'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\r\n",
    "        'degree' : np.arange(2,5)\r\n",
    "    },\r\n",
    "    {\r\n",
    "        'n_estimators' : np.arange(10, 70, 10)\r\n",
    "    },\r\n",
    "    {\r\n",
    "        'booster' : ['gbtree', 'gblinear', 'dart'],\r\n",
    "        'eta' : np.arange(0.1,0.9,0.2)\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "data_size = [0] + list(range(50,501,200))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"range\") to list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-74f10faf79f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdata_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m501\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"range\") to list"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class MachineLearningTechnique():\r\n",
    "    def __init__(self, model, reduction):\r\n",
    "        self.model = model\r\n",
    "        self.reduction = reduction\r\n",
    "\r\n",
    "    def score(self, X_test, y_test): \r\n",
    "        self.score = self.test_score = self.model.score(X_test, y_test) # changer par la fonction qui permet de discriminer les models\r\n",
    "        return self.score \r\n",
    "\r\n",
    "    def save(self):\r\n",
    "        joblib.dump(best_model,'./model.sav')\r\n",
    "        if self.reduction is not None:\r\n",
    "            joblib.dump(self.reduction, './reduction.sav')\r\n",
    "\r\n",
    "    def displayMetrics(self, X_test, y_test):\r\n",
    "        X_test = reduction.transform(X_test)\r\n",
    "        print('Best score : ', self.score)\r\n",
    "        print('Best reduction : ', self.reduction)\r\n",
    "        if self.reduction is not None:\r\n",
    "            print('Best size : ', self.reduction.n_component)\r\n",
    "        predictions = self.model.predict(X_test)\r\n",
    "        print('Model : ', self.model)\r\n",
    "        sk_report = classification_report(\r\n",
    "            digits=6,\r\n",
    "            y_true=y_test, \r\n",
    "            y_pred=predictions\r\n",
    "        )\r\n",
    "        print(sk_report)\r\n",
    "        plot_confusion_matrix_from_data(y_test, predictions,columns=['non normal','normal'])\r\n",
    "        plot_roc_curve(self.model, X_test, y_test)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"technique = RandomForestClassifier()\r\n",
    "red = None\r\n",
    "print(grid_params[0])\r\n",
    "grid = GridSearchCV(estimator=technique, param_grid=grid_params[0])\r\n",
    "grid.fit(X_train_origin, y_train)\r\n",
    "print(grid.best_estimator_)\r\n",
    "model = MachineLearningTechnique(grid.best_estimator_, red)\r\n",
    "model.displayMetrics(X_test_origin, y_test)\"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'technique = RandomForestClassifier()\\nred = None\\nprint(grid_params[0])\\ngrid = GridSearchCV(estimator=technique, param_grid=grid_params[0])\\ngrid.fit(X_train_origin, y_train)\\nprint(grid.best_estimator_)\\nmodel = MachineLearningTechnique(grid.best_estimator_, red)\\nmodel.displayMetrics(X_test_origin, y_test)'"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_model = None\r\n",
    "best_score = -1\r\n",
    "\r\n",
    "for reduction in dimention_reduction:\r\n",
    "    print(reduction)\r\n",
    "    for size in data_size:\r\n",
    "        print(size)\r\n",
    "        X_train = X_train_origin.copy()\r\n",
    "        X_test = X_test_origin.copy()\r\n",
    "        red = None\r\n",
    "        if size != 0: # cas ou l'on fait une reduction de dimension\r\n",
    "            red = reduction(n_components=size)\r\n",
    "            try:\r\n",
    "                X_train = red.fit_transform(X_train, y_train)\r\n",
    "            except Exception as e:\r\n",
    "                print(e)\r\n",
    "                print(reduction)\r\n",
    "                print('fin')\r\n",
    "                continue\r\n",
    "            X_test = red.transform(X_test)\r\n",
    "        for i in range(len(techniques)):\r\n",
    "            print(techniques[i])\r\n",
    "            grid = GridSearchCV(estimator=techniques[i], param_grid=grid_params[i])\r\n",
    "            grid_result = grid.fit(X_train, y_train)\r\n",
    "            model = MachineLearningTechnique(grid_result.best_estimator_, red)\r\n",
    "            test_score = model.score(X_test, y_test)\r\n",
    "            if test_score > best_score:\r\n",
    "                best_model = model\r\n",
    "                best_score = test_score\r\n",
    "                \r\n",
    "best_model.displayMetrics(X_test, y_test)\r\n",
    "best_model.save()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'sklearn.decomposition._pca.PCA'>\n",
      "0\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "200\n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jleva\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:561: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "400\n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jleva\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:561: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>\n",
      "0\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "200\n",
      "RandomForestClassifier()\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jleva\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "400\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\jleva\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "<class 'sklearn.manifold._locally_linear.LocallyLinearEmbedding'>\n",
      "0\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "200\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "400\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "<class 'sklearn.random_projection.SparseRandomProjection'>\n",
      "0\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "200\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "400\n",
      "RandomForestClassifier()\n",
      "KNeighborsClassifier()\n",
      "SVC()\n",
      "AdaBoostClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None)\n",
      "Best score :  0.5087719298245614\n",
      "Best reduction :  None\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 400 features, but DecisionTreeClassifier is expecting 504 features as input.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-6904e2453d81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplayMetrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-09cceaa4d79c>\u001b[0m in \u001b[0;36mdisplayMetrics\u001b[1;34m(self, X_test, y_test)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Best size : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_component\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         sk_report = classification_report(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[0;32m    408\u001b[0m                                     reset=False)\n\u001b[0;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\GCMS\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 400 features, but DecisionTreeClassifier is expecting 504 features as input."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparaison avec un Humain (Test non complet pour le moment)\r\n",
    "bertrandp-20190201 : 3 + 4 -> 4<br>\r\n",
    "settouchei-20190424 : 2 + 3 -> 2<br>\r\n",
    "mangonim-20190717 : 0 -> 0<br>\r\n",
    "syh-20190912 : 2 -> 2<br>\r\n",
    "mastourab-20190219 : 1 (+2 ?) -> 1;4;2<br>\r\n",
    "chesinara-20191009 : 3 -> 3<br>\r\n",
    "husica-20191108 : 1 + 3 + 4 -> 1<br>\r\n",
    "bruyelleCn-20191017 : 3 -> 3<br>\r\n",
    "dimolad-20190909 : 2 -> 2<br>\r\n",
    "botafemmin-20190225 : 1 -> 1<br>\r\n",
    "colakeram-20190923 : 0 ? (sinon 2) -> 0<br>\r\n",
    "heriquem-20190329 : 4 ? (cinnamate) -> 5<br>\r\n",
    "durmc-20190724 : 0 ? -> 4<br>\r\n",
    "piechockil-20190910 : 1 + 4 -> 3;4<br>\r\n",
    "heriquem-20190329 : 3 -> 5<br>\r\n",
    "genouxm-20190401 : 2 + 3 -> 2<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_test = [0,0,1,0,0,0,0,0,0,0,1,0,1,0,0,0]\r\n",
    "y_predict = [0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0]\r\n",
    "\r\n",
    "sk_report = classification_report(\r\n",
    "    digits=6,\r\n",
    "    y_true=y_test, \r\n",
    "    y_pred=y_predict\r\n",
    ")\r\n",
    "print(sk_report)\r\n",
    "plot_confusion_matrix_from_data(y_test, y_predict,columns=['non normal','normal'])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "traceback": [
      "Error: Session cannot generate requests",
      "at w.executeCodeCell (c:\\Users\\jleva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1046824664\\out\\client\\extension.js:90:320068)",
      "at w.execute (c:\\Users\\jleva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1046824664\\out\\client\\extension.js:90:319389)",
      "at w.start (c:\\Users\\jleva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1046824664\\out\\client\\extension.js:90:315205)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\jleva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1046824664\\out\\client\\extension.js:90:329732)",
      "at async t.CellExecutionQueue.start (c:\\Users\\jleva\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1046824664\\out\\client\\extension.js:90:329272)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c4dcd3a071dd88a141e61cb3846a3ad57c7a576061c6011e309b7dc0280f508"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('GCMS': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}